# -*- coding: utf-8 -*-
"""Wakka_Internship_Task_3.ipynb

Automatically generated by Colaboratory

Original file is located at
    https://colab.research.google.com/drive/1SrcK-aDKSWHMcBWJU1Zq5ruOylx7SFRL

###Importing necessary libraries
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import time

"""### Creating the fake data

"""

np.random.seed(42)


def create_fake_data(num_samples,num_features):

  X = np.random.rand(num_samples,num_features)

  # make b_ij and C_ij ∈ [-1,1]  ∀ i,j

  b= np.random.rand(num_features)
  b=2*b -1

  C = np.random.rand(num_features,num_features)
  C = 2*C -1

  n = X.shape[0]
  m = X.shape[1]
  Y = np.zeros(n)


  for i in range(n):
      dot_product = np.dot(X[i], b)
      weighted_sum = np.sum(np.outer(X[i], X[i]) * C)
      Y[i] = dot_product + weighted_sum



  Y_min = np.min(Y)
  Y_max = np.max(Y)

  Y_scaled = (Y - Y_min) / (Y_max-Y_min)
  Y_scaled = 2*Y_scaled -1


  #Adding random noise from the uniform distribution

  noise  = np.random.uniform(-0.1,0.1,size =len(Y))

  Y_scaled_with_noise = Y_scaled+noise


  return X, Y_scaled_with_noise




X,Y = create_fake_data(10000,15)

"""### Data checking

"""

X

Y

X.shape

Y.shape

#random_state is used to shuffle the data before splitting it into training and testing sets.
#splitting the data , 60% for training and the rest 40% for test and validation.

X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=42)
X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

X_train.shape,Y_train.shape

X_val.shape,Y_val.shape

X_test.shape , Y_test.shape

"""### The model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import regularizers
from tensorflow.keras.optimizers import Adam

#Regularization parameter
lmbda = 0

# We use linear activation functoin at the output layer so the model would be able to predict also negative values.

model = Sequential([
    Dense(units=128, input_shape=(X_train.shape[1],), activation='relu', kernel_regularizer=regularizers.l2(lmbda)),
    Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(lmbda)),
    Dense(units=1, activation='linear', kernel_regularizer=regularizers.l2(lmbda)),
])

model.compile(optimizer=Adam(learning_rate=0.000008), loss="mean_squared_error")

#These lines create empty lists train_accuracies ,val_accuracies and loss to store training and validation accuracies,and the loss as well.

train_accuracies = []
val_accuracies = []
train_losses = []

# We consider a good prediction if | y_pred - y_real | <= 0.2
threshold = 0.2

num_of_epochs =15


start_time = time.time()

for epoch in range(num_of_epochs):

    history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=1, verbose=0)

    Y_pred_train = model.predict(X_train)
    # Evaluate predictions at each epoch
    correct__test_pred = 0
    for i in range(len(Y_train)):
       if np.abs(Y_train[i] - Y_pred_train[i]) <=threshold:
            correct__test_pred +=1
    train_accuracy = correct__test_pred / len(Y_train)
    train_accuracies.append(train_accuracy)


    train_loss = history.history['loss'][0]
    train_losses.append(train_loss)




    Y_pred_val = model.predict(X_val)
    # Evaluate validation predictions
    correct_val_pred = 0
    for i in range(len(Y_val)):
        if np.abs(Y_val[i] - Y_pred_val[i]) <= threshold:
          correct_val_pred +=1

    val_accuracy = correct_val_pred / len(Y_val)
    val_accuracies.append(val_accuracy)

    print(f"Epoch {epoch + 1}/{num_of_epochs} - "
                 f"Training Accuracy: {train_accuracy * 100:.2f}% - "
                 f"Validation Accuracy: {val_accuracy * 100:.2f}%")

end_time = time.time()
running_time_in_sec = round(end_time-start_time , 2)
print(f"Model runnning time in min = {round(running_time_in_sec/60,2)}")

"""### Plots"""

#plt.figure(figsize=(10, 8))
    #plt.subplot(2, 1, 1)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""### Testing out model on unseen data

"""

test_predictions = model.predict(X_test)
correct_pred_test = 0

for i in range(len(Y_test)):
    if np.abs(Y_test[i] - test_predictions[i]) <= threshold:
        correct_pred_test += 1

total_examples_test = len(Y_test)
test_accuracy = correct_pred_test / total_examples_test

print(f"Test Accuracy: {test_accuracy:.2%}")

test_predictions = test_predictions.flatten()
Y_test = Y_test.flatten()

#comparing Y_predicted vs Y_test_real

import pandas as pd
df = pd.DataFrame({'Y_predicted': test_predictions, 'Y_test_real': Y_test})
df